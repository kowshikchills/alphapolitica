{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('data/data_compiled_final_may_2023.csv')\n",
    "df['uploader']=[i.split(' ')[0] for i in df['uploader']]\n",
    "df = df[['ids','upload_date','duration','comment_count','view_count','uploader']]\n",
    "df = df.fillna(0)\n",
    "df['upload_date'] = [str(int(i)) for i in df['upload_date']]\n",
    "df['upload_date'] = pd.to_datetime(df['upload_date'],format='%Y%m%d')\n",
    "df_sentiment = pd.read_csv('data/data_compiled_final_may_2023_sentiment.csv')\n",
    "senti_dict = dict(zip(df_sentiment.ids, df_sentiment.sentiment))\n",
    "df['sentiment'] = [senti_dict[i] for i in df['ids'].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "uploader\n",
    "'''\n",
    "df_uploader = df[['uploader','upload_date','duration','comment_count','view_count','sentiment']]\n",
    "df_uploader.to_csv('/Users/kowshik/projects/personal/alphapolitica_streamlit/UIdata/uploader.csv',index= False)\n",
    "\n",
    "\n",
    "'''\n",
    "dummy data\n",
    "'''\n",
    "\n",
    "df_original = pd.read_csv('data/intermediate_results')\n",
    "df_original['translated'] = df_original['translated'].fillna('')\n",
    "tags = [i for i in df_original.columns[10:] if 'proba_' not in i]\n",
    "df_original['english_translated'] = [1 if 'a' in i else 0 for i in df_original['translated'].values]\n",
    "\n",
    "df_tags = df.copy()\n",
    "\n",
    "for tag in tags:\n",
    "    found = []\n",
    "    for i in range(len(df_original)):\n",
    "        proba = df_original['proba_'+tag].values[i]\n",
    "        regex = df_original[tag].values[i]\n",
    "        eng = df_original['english_translated'].values[i]\n",
    "        if regex == 1:\n",
    "            found.append(1)\n",
    "        else:\n",
    "            if eng == 0:\n",
    "                found.append(0)\n",
    "            elif proba >0.7:\n",
    "                found.append(1)\n",
    "            else:\n",
    "                found.append(0)\n",
    "    df_tags[tag] = found\n",
    "\n",
    "''' \n",
    "Faces\n",
    "'''\n",
    "\n",
    "with open(\"data/facerec_results.txt\", \"r\") as fp:\n",
    "    person_dict = json.load(fp)\n",
    "df_attributes = pd.read_excel('data/alphapolitica_faces_attributes.xlsx')\n",
    "\n",
    "with open(\"data/facerec_results.txt\", \"r\") as fp:\n",
    "    person_dict = json.load(fp)\n",
    "faces_id = list(person_dict.keys())\n",
    "person_dict_updated = {}\n",
    "for id_ in faces_id:\n",
    "    output = person_dict[id_]\n",
    "    df_id = pd.DataFrame()\n",
    "    df_id['output'] = output\n",
    "    df_id['output_id'] = output = [i[:11] for i in output]\n",
    "    df_id['rank'] = np.arange(len(df_id))\n",
    "    df_id['count'] = 1\n",
    "    df_grouped = df_id.groupby('output_id').aggregate({'rank':np.min, 'count':np.sum}).reset_index()\n",
    "    df_grouped = df_grouped.sort_values('rank')\n",
    "    df_ranked = df_grouped[df_grouped['rank'] < len(df_id)/1.5]\n",
    "    df_ranked = df_ranked[df_ranked['count'] > 1]\n",
    "    person_dict_updated[id_] = df_ranked['output_id'].values\n",
    "df_attributes = pd.read_excel('data/alphapolitica_faces_attributes.xlsx')\n",
    "df_attributes = df_attributes[df_attributes.image_id.isin(list(person_dict_updated.keys()))]\n",
    "df_attributes['number'] = [len(person_dict_updated[i]) for i in df_attributes.image_id]\n",
    "df_ = df_attributes[df_attributes['Gender'] == 'F']\n",
    "to_drop = df_[df_.number>800]['image_id'].values\n",
    "to_drop = list(set(to_drop)- set(['nagari.png']))\n",
    "\n",
    "\n",
    "df_faces = df.copy()\n",
    "faces_id = set(list(person_dict_updated.keys()))-set(to_drop)\n",
    "lis_ = []\n",
    "for f_id in faces_id:\n",
    "    if f_id in df_attributes.image_id.values:\n",
    "        faces_dict =  dict(Counter([i[:11] for i in person_dict_updated[f_id]]))\n",
    "        df_faces[f_id] = [faces_dict[i] if i in faces_dict.keys() else 0 for i in df_faces.ids]\n",
    "\n",
    "df_attributes = pd.read_excel('data/alphapolitica_faces_attributes.xlsx')\n",
    "df_attributes['Age'] = [int(i) for i in df_attributes['Age'].fillna(np.mean(df_attributes['Age']))]\n",
    "coords = []\n",
    "df_attributes['loc'] = df_attributes['loc'].fillna('')\n",
    "for i in range(len(df_attributes)):\n",
    "    loc = df_attributes['loc'].values[i].replace(' ','')\n",
    "    if loc != '':\n",
    "        if '째N' in loc:\n",
    "            lat = loc.split('째N')[0].strip()\n",
    "            long = loc.split('째N')[1].split('째E')[0].strip()\n",
    "            coords.append(lat+long)\n",
    "        else:\n",
    "            coords.append(loc)\n",
    "    else:\n",
    "        coords.append('0,0')\n",
    "\n",
    "df_attributes['coords'] = coords\n",
    "del df_attributes['loc']\n",
    "df_attributes.to_excel('/Users/kowshik/projects/personal/alphapolitica_streamlit/UIdata/alphapolitica_faces_attributes_coords.xlsx', index = False)\n",
    "df_faces.to_csv('/Users/kowshik/projects/personal/alphapolitica_streamlit/UIdata/faces.csv', index = False)\n",
    "df_tags.to_csv('/Users/kowshik/projects/personal/alphapolitica_streamlit/UIdata/tags.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/facerec_results.txt\", \"r\") as fp:\n",
    "    person_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['palakonda.png',\n",
       " 'tirupati_l2.png',\n",
       " 'vijayawada_central.png',\n",
       " 'mada.png',\n",
       " 'kavali.png',\n",
       " 'mantralayam.png',\n",
       " 'puttaparthi.png',\n",
       " 'pathapatnam.png',\n",
       " 'cheepurupali.png',\n",
       " 'tenali.png',\n",
       " 'panyam.png',\n",
       " 'guntur_east.png',\n",
       " 'rajahmundry_rural.png',\n",
       " 'tiruvuru.png',\n",
       " 'machillipatnam.png',\n",
       " 'pileru.png',\n",
       " 'pattikonda.png',\n",
       " 'gannavaram.png',\n",
       " 'yerragondapalem.png',\n",
       " 'gajapathinagram.png',\n",
       " 'narsapuram.png',\n",
       " 'srisailam.png',\n",
       " 'paturi_nagabhusnam.png',\n",
       " 'chodavaram.png',\n",
       " 'venkatagiri.png',\n",
       " 'madugula.png',\n",
       " 'denduluru.png',\n",
       " 'vizianagaram_.png',\n",
       " 'Etcherla.png',\n",
       " 'araku_valley.png',\n",
       " 'amalapuram.png',\n",
       " 'achanta.png',\n",
       " 'badvel.png',\n",
       " 'amalapuram_l.png',\n",
       " 'narsapuram_l.png',\n",
       " 'prathipadu_.png',\n",
       " 'kurnool_l.png',\n",
       " 'vishakapatnam_east.png',\n",
       " 'vijay_kumar.png',\n",
       " 'undi.png',\n",
       " 'visakapatnam.png',\n",
       " 'tadikonda.png',\n",
       " 'nellore_rural.png',\n",
       " 'vinukonda.png',\n",
       " 'vishakapatnam_west.png',\n",
       " 'mandanapalli.png',\n",
       " 'kandukur.png',\n",
       " 'guntur_west.png',\n",
       " 'penamaluru.png',\n",
       " 'pamarru.png',\n",
       " 'kakinada_.png',\n",
       " 'nandikotkur.png',\n",
       " 'kuppam.png',\n",
       " 'razole.png',\n",
       " 'jaggampeta.png',\n",
       " 'nuzvid.png',\n",
       " 'tadipatri.png',\n",
       " 'karanam.png',\n",
       " 'thamballapalle.png',\n",
       " 'guntur_l.png',\n",
       " 'nidadavole.png',\n",
       " 'payakaropet.png',\n",
       " 'raghu.png',\n",
       " 'tekkali.png',\n",
       " 'Narasannapeta.png',\n",
       " 'Amadalavasa.png',\n",
       " 'kothapeta.png',\n",
       " 'repalle.png',\n",
       " 'anaparty.png',\n",
       " 'nandyal.png',\n",
       " 'proddatur.png',\n",
       " 'satyavedu.png',\n",
       " 'pedana.png',\n",
       " 'polavaram.png',\n",
       " 'gandhar_nellore.png',\n",
       " 'kadapa.png',\n",
       " 'salur.png',\n",
       " 'santhanuyhalapadu.png',\n",
       " 'alur.png',\n",
       " 'penukonda.png',\n",
       " 'palakollu.png',\n",
       " 'pithapuram.png',\n",
       " 'tuni.png',\n",
       " 'komeni_srinivasrao.png',\n",
       " 'yelamanchili.png',\n",
       " 'ramchandrapuram.png',\n",
       " 'anantapur_urban.png',\n",
       " 'araku.png',\n",
       " 'posani.png',\n",
       " 'ayyanna_patrudu.png',\n",
       " 'nellore_city.png',\n",
       " 'ankapalle.png',\n",
       " 'ponnuru.png',\n",
       " 'kvp_ramchandraravu.png',\n",
       " 'Govardhan Reddy.png',\n",
       " 'tanuku.png',\n",
       " 'narasaraopet_l.png',\n",
       " 'palasa.png',\n",
       " 'gopalapuram.png',\n",
       " 'cm_ramesh.png',\n",
       " 'rajinikanth.png',\n",
       " 'gudur.png',\n",
       " 'addanki.png',\n",
       " 'Rajam.png',\n",
       " 'rapka.png',\n",
       " 'jammalamadugu.png',\n",
       " 'sarvepalli.png',\n",
       " 'jaggayyapeta.png',\n",
       " 'tirupathi.png',\n",
       " 'nageswara_rao.png',\n",
       " 'nagari.png',\n",
       " 'vizianagaram.png',\n",
       " 'Buddha _Venkanna.png',\n",
       " 'Pendurthi.png',\n",
       " 'nellore_l.png',\n",
       " 'baptla_l.png',\n",
       " 'rambhupal_reddy.png',\n",
       " 'roja.png',\n",
       " 'kakinada_city.png',\n",
       " 'tadepalligudem.png',\n",
       " 'eluru.png',\n",
       " 'Advocate _Sravan Kumar.png',\n",
       " 'Nimmakayala _China _Rajappa.png',\n",
       " 'chandragiri.png',\n",
       " 'narasaraopet.png',\n",
       " 'ichanapuram.png',\n",
       " 'singanamala.png',\n",
       " 'jagan_sir.png',\n",
       " 'kondapi.png',\n",
       " 'kodur.png',\n",
       " 'satyanarayan.png',\n",
       " 'bonda_uma.png',\n",
       " 'kakinada.png',\n",
       " 'yemmiganur.png',\n",
       " 'rajmundry_city.png',\n",
       " 'kaikuluru.png',\n",
       " 'pedakurapadu.png',\n",
       " 'venkat_krishna.png',\n",
       " 'kovur.png',\n",
       " 'JOGI_RAMESH.png',\n",
       " 'myalavaram.png',\n",
       " 'ongole_l.png',\n",
       " 'kanigiri.png',\n",
       " 'palamaner.png',\n",
       " 'avvinigada.png',\n",
       " 'atmakur.png',\n",
       " 'Srungavarapukota.png',\n",
       " 'guntakal.png',\n",
       " 'kurupam.png',\n",
       " 'chitoor_l.png',\n",
       " 'durgesh.png',\n",
       " 'Nellimarla.png',\n",
       " 'guruzala.png',\n",
       " 'rayadrug.png',\n",
       " 'myudukur.png',\n",
       " 'krishna.png',\n",
       " 'murali_krishna.png',\n",
       " 'rajempet.png',\n",
       " 'gannavaram_vamsi.png',\n",
       " 'bhimili.png',\n",
       " 'macherala.png',\n",
       " 'lokesh.png',\n",
       " 'anakapalli.png',\n",
       " 'vijayawada_east.png',\n",
       " 'Venkata_Mahesh.png',\n",
       " 'vishakapatnam_south.png',\n",
       " 'kodali_nani.png',\n",
       " 'dhone.png',\n",
       " 'kodumur.png',\n",
       " 'machillipatnma_l.png',\n",
       " 'punganur.png',\n",
       " 'pravathipuram.png',\n",
       " 'elluru_l.png',\n",
       " 'deepak_reddy.png',\n",
       " 'chirala.png',\n",
       " 'kamalapuram.png',\n",
       " 'mummidivaram.png',\n",
       " 'srikakulam.png',\n",
       " 'parchur.png',\n",
       " 'prathipadu.png',\n",
       " 'sridevi.png',\n",
       " 'udayagiri.png',\n",
       " 'chitoor.png',\n",
       " 'chilakuluripet.png',\n",
       " 'peddapuram.png',\n",
       " 'kadapa_l.png',\n",
       " 'Nandigam_Suresh.png',\n",
       " 'mangalagiri.png',\n",
       " 'unguturu.png',\n",
       " 'monohar.png',\n",
       " 'chandra_babu.png',\n",
       " 'bhoomi_reddy.png',\n",
       " 'ongole.png',\n",
       " 'vishakapatnam_north.png',\n",
       " 'mohan_nandigam.png',\n",
       " 'vemuru.png',\n",
       " 'darsi.png',\n",
       " 'rajini.png',\n",
       " 'nandyal_l.png',\n",
       " 'markapuram.png',\n",
       " 'kadiri.png',\n",
       " 'mandapeta.png',\n",
       " 'kurnool.png',\n",
       " 'sambasivarao.png',\n",
       " 'tirupati_l.png',\n",
       " 'ramkumar_reddy.png',\n",
       " 'raptadu.png',\n",
       " 'kovvur.png',\n",
       " 'sullurpeta.png',\n",
       " 'bobili.png',\n",
       " 'ATCHANNAIDU .png',\n",
       " 'kethireddy.png',\n",
       " 'vijayawada_l.png',\n",
       " 'pulivendula.png',\n",
       " 'APPALARAJU.png',\n",
       " 'paderu.png',\n",
       " 'pawan.png',\n",
       " 'ramana_reddy.png',\n",
       " 'sattenapalli.png',\n",
       " 'banaganapalle.png',\n",
       " 'Bharat.png',\n",
       " 'gudivada.png',\n",
       " 'rajempet_l.png',\n",
       " 'srikakulam_.png',\n",
       " 'puthalapattu.png',\n",
       " 'chintalapudi.png',\n",
       " 'murthy.png',\n",
       " 'vishnu.png',\n",
       " 'adoni.png',\n",
       " 'kalayan_durg.png',\n",
       " 'srikalahasti.png',\n",
       " 'giddalaur.png',\n",
       " 'bhimavaram.png',\n",
       " 'vijayawada_west.png',\n",
       " 'hindupur_l.png',\n",
       " 'urvakonda.png',\n",
       " 'rangaram.png',\n",
       " 'baptla.png',\n",
       " 'anantapur_l.png',\n",
       " 'rajsekhar.png',\n",
       " 'dharmavaram.png',\n",
       " 'rampochandavram.png',\n",
       " 'Botsa Satyanarayana .png',\n",
       " 'perni_nani.png',\n",
       " 'rayachoti.png',\n",
       " 'Telakapalli_Ravi.png',\n",
       " 'hindupur.png',\n",
       " 'allagadda.png',\n",
       " 'Chelluboyina.png',\n",
       " 'srinivas_reddy.png',\n",
       " 'sajjala.png',\n",
       " 'avinash.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(person_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv('data/data_compiled_final_may_2023.csv')\n",
    "df['uploader']=[i.split(' ')[0] for i in df['uploader']]\n",
    "df = df[['ids','upload_date','duration','comment_count','view_count','uploader']]\n",
    "df = df.fillna(0)\n",
    "df['upload_date'] = [str(int(i)) for i in df['upload_date']]\n",
    "df['upload_date'] = pd.to_datetime(df['upload_date'],format='%Y%m%d')\n",
    "df_sentiment = pd.read_csv('data/data_compiled_final_may_2023_sentiment.csv')\n",
    "senti_dict = dict(zip(df_sentiment.ids, df_sentiment.sentiment))\n",
    "df['sentiment'] = [senti_dict[i] for i in df['ids'].values]\n",
    "\n",
    "with open(\"data/facerec_results.txt\", \"r\") as fp:\n",
    "    person_dict = json.load(fp)\n",
    "df_attributes = pd.read_excel('data/alphapolitica_faces_attributes.xlsx')\n",
    "\n",
    "df_faces = df.copy()\n",
    "faces_id = list(person_dict.keys())\n",
    "lis_ = []\n",
    "for f_id in faces_id:\n",
    "    if f_id in df_attributes.image_id.values:\n",
    "        faces_dict =  dict(Counter([i[:11] for i in person_dict[f_id]]))\n",
    "        df_faces[f_id] = [faces_dict[i] if i in faces_dict.keys() else 0 for i in df_faces.ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open(\"data/facerec_results.txt\", \"r\") as fp:\n",
    "    person_dict = json.load(fp)\n",
    "faces_id = list(person_dict.keys())\n",
    "person_dict_updated = {}\n",
    "for id_ in faces_id:\n",
    "    output = person_dict[id_]\n",
    "    df = pd.DataFrame()\n",
    "    df['output'] = output\n",
    "    df['output_id'] = output = [i[:11] for i in output]\n",
    "    df['rank'] = np.arange(len(df))\n",
    "    df['count'] = 1\n",
    "    df_grouped = df.groupby('output_id').aggregate({'rank':np.min, 'count':np.sum}).reset_index()\n",
    "    df_grouped = df_grouped.sort_values('rank')\n",
    "    df_ranked = df_grouped[df_grouped['rank'] < len(df)/2]\n",
    "    df_ranked = df_ranked[df_ranked['count'] > 2]\n",
    "    person_dict_updated[id_] = df_ranked['output_id'].values\n",
    "df_attributes = pd.read_excel('data/alphapolitica_faces_attributes.xlsx')\n",
    "df_attributes = df_attributes[df_attributes.image_id.isin(list(person_dict_updated.keys()))]\n",
    "df_attributes['number'] = [len(person_dict_updated[i]) for i in df_attributes.image_id]\n",
    "df_ = df_attributes[df_attributes['Gender'] == 'F']\n",
    "to_drop = df_[df_.number>800]['image_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rajmundry_city.png', 'chilakuluripet.png', 'pattikonda.png',\n",
       "       'anakapalli.png', 'amalapuram_l.png'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attributes = pd.read_excel('data/alphapolitica_faces_attributes.xlsx')\n",
    "df_attributes['Age'] = [int(i) for i in df_attributes['Age'].fillna(np.mean(df_attributes['Age']))]\n",
    "df_attributes['constituency'] = df_attributes['Name']\n",
    "#Add real coordinates and constituency here\n",
    "\n",
    "\n",
    "poly = Polygon([(17.298641, 79.687922),\n",
    " (16.861628, 81.643629),\n",
    " (14.884918, 79.717799),\n",
    " (14.994391, 77.257505)])\n",
    "\n",
    "def polygon_random_points (poly, num_points):\n",
    "    min_x, min_y, max_x, max_y = poly.bounds\n",
    "    points = []\n",
    "    while len(points) < num_points:\n",
    "            random_point = Point([random.uniform(min_x, max_x), random.uniform(min_y, max_y)])\n",
    "            if (random_point.within(poly)):\n",
    "                points.append(random_point)\n",
    "    return points\n",
    "\n",
    "points = polygon_random_points(poly,len(df_attributes))\n",
    "coords = []\n",
    "for p in points:\n",
    "    coords.append(str(p.x) +\",\"+str(p.y))\n",
    "df_attributes['coords'] = coords\n",
    "df_attributes.to_excel('/Users/kowshik/projects/personal/alphapolitica_streamlit/UIdata/alphapolitica_faces_attributes_coords.xlsx', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/intermediate_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('alphapenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "277fab76d0acca917d9ff45691135e5555c82671ab771a82f606bf05d4140469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
